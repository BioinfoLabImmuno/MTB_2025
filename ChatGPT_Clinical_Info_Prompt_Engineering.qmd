---
title: "ChatGPT for Clinical Information Research: Prompt-Engineering Playbook"
author: ""
format:
  html:
    toc: true
    toc-depth: 3
    number-sections: true
    code-fold: false
execute:
  echo: false
  eval: true
---

# Purpose

A practical playbook for using ChatGPT to support clinical information research and evidence synthesis, with ready-to-use prompt recipes and domain-specific prompts for prokaryotic gene prediction.

# Ground Rules for Reliable, Auditable Outputs

- **Role and audience**: Define who the assistant is and whom the output serves.
- **Task constraints**: Specify scope, time window, patient population, outcomes.
- **Citations**: Request numbered citations with links and dates; favor guidelines, systematic reviews, and RCTs.
- **Structure**: Ask for tables, bullet lists, and short rationale (no chain-of-thought).
- **Safety**: No medical advice; evidence summaries only.
- **Recency**: Prioritize sources from the last 3–5 years while including seminal older works when needed.

# Reusable Prompt Template

```
You are a clinical information specialist. Topic: [condition/intervention].
Audience: [who]. Setting: [where].
Do:
1) PICO table.
2) Draft search strategy: key terms (MeSH/Emtree + free text), Boolean blocks, databases (PubMed, Embase, Cochrane), date limits.
3) Summarize 5–8 best sources (guidelines/SR/RCTs) with 1-line takeaways, year, and link (numbered citations).
4) Evidence synthesis (bullets).
5) Applicability/risks; 6) Gaps/next steps.
Requirements: concise, structured; prioritize last 5 years; include any major older landmark.
Do not give medical advice; provide evidence summaries only.
```

# Handy Micro-Prompts

- **Quick PICO builder**  
```
Build a PICO for [question]. State assumptions explicitly. Output as a 4-row table.
```
- **Search strategy refinement**  
```
Convert this clinical question into a PubMed search: list MeSH + free text, Boolean blocks,
filters (dates, humans, RCTs). Then produce an Embase version with Emtree.
```
- **Evidence mapping**  
```
Create an evidence map: columns = Study type | Year | Population | Comparator | Primary outcome | Direction of effect | Risk of bias (brief).
```
- **Bias and limitations**  
```
In 5 bullets, list key biases/limitations in the current evidence base for [topic].
```

# Output Skeletons

## PICO (table)
| Element | Details |
|---|---|
| Population |  |
| Intervention |  |
| Comparator |  |
| Outcomes |  |

## Top Sources (example pattern)
1. [Year] [Type]: key finding. Link.  
2. [Year] [Type]: key finding. Link.  

## Synthesis
- Consistent findings  
- Divergences  
- Effect sizes (if available)  
- Safety signals  
- Practice implications  

## Applicability and Risks
- Setting fit, patient selection, resource constraints, equity considerations.

# Domain-Specific Prompts: Prokaryotic Gene Prediction

## Level 3 Prompt (Rule-Based vs Machine Learning)

```
Role: Bioinformatics methodologist. Audience: graduate researchers.
Task: In the context of prokaryotic gene prediction, compare rule-based methods vs machine learning–based methods and discuss effectiveness in identifying genes in bacterial genomes.
Scope: Bacteria (complete and draft genomes), include small ORFs and operon context.
Structure:
1) One-paragraph overview (≤120 words).
2) Comparison table with rows: Assumptions | Features used | Training data needs | Handling of atypical GC content | Small ORFs | Horizontal gene transfer | Runtime/scale | Typical precision/recall.
3) Brief case notes on representative tools (e.g., Prodigal, GLIMMER, GeneMark, MetaGeneMark, newer ML approaches).
4) Failure modes (false starts, overlapping genes, atypical codon usage).
5) Evaluation: datasets & metrics (precision/recall/F1; gene start accuracy).
6) Practical guidance: which to pick for [genome qualities: GC%, metagenome vs isolate], with 3 actionable tips.
Citations: numbered, links; include recent benchmarks and seminal tools. Avoid chain-of-thought; provide key steps only.
```

## Level 4 Prompt (Challenges, Advances, CNN/RNN/Transformers)

```
Role: Senior bioinformatics researcher advising on bacterial gene prediction pipeline design.
Task: Explain current challenges and advancements in gene prediction for bacterial genomes; show how ML models (CNNs, RNNs, Transformers, gradient boosting) address them.
Must cover:
- Data issues: small ORFs, atypical codon usage, GC bias, horizontally transferred genes, fragmented contigs/metagenomes.
- Feature engineering vs representation learning (k-mers, codon usage, coding potential, signal vs content models).
- Architectures: CNNs for motif/signal capture (promoters, RBS), RNNs for sequence context, Transformers for long-range dependencies; pros/cons vs HMMs.
- Training regimes: self-supervision, weak labels from curated genomes, transfer learning across taxa; class imbalance handling.
- Evaluation & generalization: cross-species benchmarks, start-site accuracy, external validation; pitfalls (data leakage).
- Integration: combine ML signals with comparative genomics/synteny and ribosome profiling validation.
Outputs:
1) Executive summary (≤150 words).
2) Challenge→Solution table.
3) Design checklist for building a modern predictor for [species/metagenome].
Citations: numbered with links (recent reviews/benchmarks + canonical tools). No chain-of-thought—provide conclusions and key steps only.
```

# Quality Control and Ethics Checklist

- Provenance: citations are present, current, and reputable.
- Transparency: limits/biases are explicitly stated.
- Reproducibility: datasets, metrics, and versions specified.
- Safety: no clinical advice; evidence only.
- Actionability: clear next steps (databases to search, tools to test, metrics to report).
