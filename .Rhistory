# install.packages(c("tidyverse","scales")) # se servono
library(tidyverse)
library(scales)
#========================
# Figura A — Per-paper (famiglie di metodi)
#========================
df_family <- tribble(
~Categoria,            ~Percent,
"Statistici classici", 51,
"Machine Learning",    31,
"Entrambi",            11,
"Non riportato",        7
)
p_family <- df_family %>%
mutate(Categoria = fct_reorder(Categoria, Percent)) %>%
ggplot(aes(x = Categoria, y = Percent)) +
geom_col(width = 0.65) +
geom_text(aes(label = paste0(Percent, "%")),
vjust = -0.35, size = 4.2) +
coord_cartesian(ylim = c(0, 60)) +
labs(title = "Tipi di modelli per-paper",
subtitle = "Confronto per famiglia di metodi",
x = NULL, y = "Frequenza (%)") +
theme_minimal(base_size = 12) +
theme(panel.grid.minor = element_blank(),
axis.text.x = element_text(face = "bold"))
p_family
#========================
# Figura B — Per-modello (metodi specifici, escluso Wynants)
#========================
df_methods <- tribble(
~Metodo,                     ~Percent,
"Cox",                       21.6,
"Logistica (pen./no)",       16.5,
"Lineare",                    1.9,
"Reti neurali",              17.9,
"Random forest",              5.9,
"Alberi (single tree)",       4.0,
"SVM",                        5.3,
"Boosting",                   4.5
) %>%
arrange(Percent)
p_methods <- df_methods %>%
mutate(Metodo = fct_reorder(Metodo, Percent)) %>%
ggplot(aes(y = Metodo, x = Percent)) +
geom_col(width = 0.6) +
geom_text(aes(label = paste0(Percent, "%")),
hjust = -0.1, size = 4.0) +
coord_cartesian(xlim = c(0, 25)) +
labs(title = "Metodi specifici per-modello",
subtitle = "Percentuali complessive (escluso Wynants)",
x = "Frequenza (%)", y = NULL) +
theme_minimal(base_size = 12) +
theme(panel.grid.minor = element_blank(),
axis.text.y = element_text(face = "bold"))
p_methods
p_family
library(tidymodels)
library(conformalClassification)
install.packages("conformalClassification")
library(tidymodels)
library(conformalClassification)
# --- dati di esempio ---
set.seed(123)
data(iris)
iris_bin <- iris %>% filter(Species != "setosa") %>%
mutate(Species = factor(Species))
split  <- initial_split(iris_bin, prop = 0.6)
train  <- training(split)
temp   <- testing(split)
split2 <- initial_split(temp, prop = 0.5)
calib  <- training(split2)
test   <- testing(split2)
# --- modello tidymodels ---
wf <- workflow() %>%
add_model(logistic_reg() %>% set_engine("glm")) %>%
add_formula(Species ~ .) %>%
fit(train)
# Predizioni su calibration set
calib_pred <- predict(wf, calib, type = "prob") %>%
bind_cols(calib %>% select(Species))
# --- conformal set ---
conf_obj <- conformalClassification(
scores = calib_pred %>% select(.pred_versicolor, .pred_virginica),
y = calib_pred$Species,
method = "APS" # Adaptive Prediction Sets
)
conformalClassification::conformalClassification
ls("package:conformalClassification")
library(conformalClassification)
# Immaginiamo che trainingSet e testSet siano data.frame con outcome nella prima colonna
pValues <- ICPClassification(trainingSet, testSet, ratioTrain = 0.7, method = "rf", nrTrees = 100)
library(dplyr)
library(conformalClassification)
# Esempio binario con iris (versicolor vs virginica)
set.seed(123)
data(iris)
iris_bin <- iris %>% filter(Species != "setosa") %>% droplevels()
split  <- rsample::initial_split(iris_bin, prop = 0.7)
trainX <- rsample::training(split)
testX  <- rsample::testing(split)
# Portare la risposta in PRIMA colonna e in data.frame base
train_df <- data.frame(Species = trainX$Species, trainX %>% select(-Species))
test_df  <- data.frame(Species = testX$Species,  testX  %>% select(-Species))
# Inductive Conformal Prediction (RF interno)
pvals <- ICPClassification(
trainingSet = train_df,
testSet     = test_df,
ratioTrain  = 0.7,      # parte di trainingSet usata per il "proper training"
method      = "rf",
nrTrees     = 500
)
# Prediction sets a livello 1-α (es. 90% → α = 0.10)
alpha   <- 0.10
classes <- levels(train_df$Species)
sets_list <- apply(pvals, 1, function(p) classes[p >= alpha])
sets_str  <- vapply(sets_list, function(s) paste0("{", paste(s, collapse=","), "}"), "")
# Valutazioni
truth     <- test_df$Species
coverage  <- mean(mapply(function(S, y) y %in% S, sets_list, truth))   # copertura empirica
set_size  <- mean(lengths(sets_list))                                  # efficienza (più piccolo = meglio)
# Metriche del pacchetto
eff  <- CPEfficiency(pvals, testLabels = truth, sigfLevel = alpha)
err  <- CPErrorRate (pvals, testLabels = truth, sigfLevel = alpha)
val  <- CPValidity  (pvals, testLabels = truth)
list(coverage = coverage, set_size = set_size,
efficiency = eff, error_rate = err, validity = val)[1:3]
######################################
library(dplyr)
library(tidymodels)
# Esempio con logistic (puoi sostituire con wf_xgb già fittato)
set.seed(123)
data(iris)
iris_bin <- iris %>% filter(Species != "setosa") %>% droplevels()
# Split: train / calib / test
sp1   <- initial_split(iris_bin, prop = 0.6)
train <- training(sp1); temp <- testing(sp1)
sp2   <- initial_split(temp, prop = 0.5)
calib <- training(sp2); test <- testing(sp2)
wf <- workflow() %>%
add_model(logistic_reg() %>% set_engine("glm")) %>%
add_formula(Species ~ .) %>%
fit(train)
mk_conformal <- function(wf, calib_df, test_df, outcome, alpha = 0.10) {
calib_df[[outcome]] <- factor(calib_df[[outcome]])
test_df [[outcome]] <- factor(test_df [[outcome]], levels = levels(calib_df[[outcome]]))
lv <- levels(calib_df[[outcome]])
# Prob sul calibration
pr_cal  <- predict(wf, calib_df, type = "prob") %>% as_tibble()
P_cal   <- pr_cal %>% select(all_of(paste0(".pred_", lv))) %>% as.matrix()
y_cal   <- as.integer(calib_df[[outcome]])
p_truth <- P_cal[cbind(seq_len(nrow(P_cal)), y_cal)]
s_cal   <- 1 - p_truth
# Soglia split-conformal
n  <- length(s_cal)
q  <- quantile(s_cal, probs = ceiling((n + 1) * (1 - alpha)) / n, type = 1, na.rm = TRUE)
thr <- 1 - as.numeric(q)
# Prob sul test e prediction sets
pr_test <- predict(wf, test_df, type = "prob") %>% as_tibble()
P_test  <- pr_test %>% select(all_of(paste0(".pred_", lv))) %>% as.matrix()
sets_list <- apply(P_test, 1, function(p) lv[p >= thr])
sets_str  <- vapply(sets_list, function(s) paste0("{", paste(s, collapse=","), "}"), "")
tibble(
set        = sets_str,
set_size   = lengths(sets_list),
threshold  = thr,
truth      = test_df[[outcome]]
) %>%
mutate(covered = mapply(function(S, y) y %in% strsplit(gsub("[{}]", "", S), ",")[[1]],
set, as.character(truth)))
}
conf_out <- mk_conformal(wf, calib, test, outcome = "Species", alpha = 0.10)
mean(conf_out$covered)   # copertura empirica ~≥ 0.90
mean(conf_out$set_size)  # efficienza
head(conf_out)
setwd("~/Desktop/plink33")
library(dplyr)
library(stringr)
# ---------- 1) Leggi i tre file ----------
f1 <- read.table("OB-1319515.txt", header=FALSE, col.names=c("SNP","OB1319515"), stringsAsFactors=FALSE, sep="", quote="")
f2 <- read.table("OB_52.txt",     header=FALSE, col.names=c("SNP","OB52"),      stringsAsFactors=FALSE, sep="", quote="")
f3 <- read.table("OB_937.txt",    header=FALSE, col.names=c("SNP","OB937"),     stringsAsFactors=FALSE, sep="", quote="")
f3
# ---------- 2) Unione per SNP e ordinamento ----------
geno <- f1 %>% full_join(f2, by="SNP") %>% full_join(f3, by="SNP") %>% arrange(SNP)
# ---------- 3) Pulizia: tieni solo AA/AB/BB, tutto il resto -> NA ----------
clean_one <- function(x){
x <- toupper(trimws(as.character(x)))
# rimuovi eventuali 'arazzi' da copia-incolla tipo "(base)" "->" ecc.
x <- gsub("[^A|B]", "", x)     # lascia solo A e B
x[!(x %in% c("AA","AB","BB"))] <- NA
x
}
geno$OB1319515 <- clean_one(geno$OB1319515)
geno$OB52      <- clean_one(geno$OB52)
geno$OB937     <- clean_one(geno$OB937)
# ---------- 4) Mappa a due alleli (A/B o 0) ----------
split_to_alleles <- function(v){
# v è un vettore di "AA","AB","BB", NA
a1 <- ifelse(is.na(v), "0", substr(v,1,1))
a2 <- ifelse(is.na(v), "0", substr(v,2,2))
cbind(a1, a2)
}
al_1319515 <- split_to_alleles(geno$OB1319515)
al_52      <- split_to_alleles(geno$OB52)
al_937     <- split_to_alleles(geno$OB937)
# ---------- 5) Costruisci PED (6 campi + 2 alleli per SNP) ----------
make_ped <- function(id, alleles2col, sex="1", pheno="2"){
# alleles2col: matrice nSNP x 2 (A1,A2) già pulita
as.character(c("FAM1", id, "0", "0", sex, pheno, as.vector(t(alleles2col))))
}
ped <- rbind(
make_ped("OB1319515", al_1319515, sex="1", pheno="2"),
make_ped("OB52",      al_52,      sex="1", pheno="2"),
make_ped("OB937",     al_937,     sex="1", pheno="2")
)
# Controllo forte: ogni riga deve avere 6 + 2*nSNP colonne
nSNP <- nrow(geno)
stopifnot(ncol(ped) == (6 + 2*nSNP))
# ---------- 6) Esporta .ped (spazio) ----------
write.table(ped, "famiglia.ped", quote=FALSE, sep=" ", row.names=FALSE, col.names=FALSE)
# ---------- 7) Esporta .map (spazio; qui posizioni fittizie) ----------
map <- data.frame(
Chr = 1,
SNP = geno$SNP,
cM  = 0,
bp  = seq_len(nSNP) * 1000
)
write.table(map, "famiglia.map", quote=FALSE, sep=" ", row.names=FALSE, col.names=FALSE)
ped
map <- read.table("famiglia.map", header=FALSE, stringsAsFactors=FALSE)
# colonna 2 del map = SNP ID
dat <- paste("M", map$V2)
writeLines(dat, "merlin.dat")
map_plink <- read.table("famiglia.map", header=FALSE, stringsAsFactors=FALSE)
# MERLIN vuole solo 3 colonne: chr, snp, posizione
map_merlin <- map_plink[, c(1,2,4)]
write.table(map_merlin, "merlin.map",
quote=FALSE, sep="\t", row.names=FALSE, col.names=FALSE)
# rimuovi eventuali colonne in eccesso
nSNP <- nrow(map)  # 592652
expected_cols <- 6 + 2*nSNP
ped <- read.table("famiglia.ped", header=FALSE, stringsAsFactors=FALSE)
setwd("~/Desktop/Lavori_perglioma22Ott/Quarto_MTB_Book")
library(tibble)
library(ggplot2)
tiers <- tribble(
~Tumore,    ~Tier,   ~Alterazione,
"Breast",   "Tier I", "ERBB2 (HER2) amplificazione/mutazioni",
"Breast",   "Tier I", "BRCA1/2 mutazioni",
"Breast",   "Tier I", "PIK3CA hotspot",
"Breast",   "Tier I", "ESR1 mutazioni",
"Breast",   "Tier II","AKT1 (E17K)",
"Breast",   "Tier II","PTEN loss/mutazioni",
"Breast",   "Tier II","HER2 mut non-amplicati",
"Breast",   "Tier II","NTRK fusioni",
"Ovario",   "Tier I", "BRCA1/2 mutazioni",
"Ovario",   "Tier I", "HRD positivo",
"Ovario",   "Tier I", "MSI-H/dMMR",
"Ovario",   "Tier I", "NTRK fusioni",
"Ovario",   "Tier II","RAD51C/D, PALB2, ATM",
"Ovario",   "Tier II","CCNE1 amplificazione",
"Ovario",   "Tier II","PIK3CA/PTEN mutazioni",
"Ovario",   "Tier II","KRAS mutazioni",
"Ovario",   "Tier II","HER2 amplificazione",
"Glioma",   "Tier I", "IDH1/2 mutazioni",
"Glioma",   "Tier I", "1p/19q codelezione",
"Glioma",   "Tier I", "MGMT metilazione",
"Glioma",   "Tier I", "MSI-H/dMMR",
"Glioma",   "Tier I", "NTRK fusioni",
"Glioma",   "Tier II","EGFR amplificazione/EGFRvIII",
"Glioma",   "Tier II","TERT promoter mutazioni",
"Glioma",   "Tier II","PTEN loss/mutazioni",
"Glioma",   "Tier II","PIK3CA mutazioni",
"Glioma",   "Tier II","CDKN2A/B delezione",
"Glioma",   "Tier II","FGFR3-TACC3 fusioni",
"Glioma",   "Tier II","MET amplificazione",
"Glioma",   "Tier II","BRAF V600E"
)
ggplot(tiers, aes(x = Tumore, y = Alterazione, fill = Tier)) +
geom_tile(color = "white") +
scale_fill_manual(values = c("Tier I" = "forestgreen",
"Tier II" = "gold",
"Tier III" = "grey70",
"Tier IV" = "grey90")) +
theme_minimal(base_size = 12) +
theme(axis.text.y = element_text(size = 9)) +
labs(title = "AMP/ASCO/CAP Variant Classification",
subtitle = "Breast, Ovario, Glioma",
fill = "Tier")
library(readr); library(dplyr); library(gt)
som <- read_csv("data/ovary_variants_somatic.csv")
germ <- read_csv("data/ovary_variants_germline.csv")
gt(som) |> tab_caption("HGSOC — Varianti somatiche")
